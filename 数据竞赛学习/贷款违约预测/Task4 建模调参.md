<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Task4 å»ºæ¨¡ä¸è°ƒå‚](#task4-%E5%BB%BA%E6%A8%A1%E4%B8%8E%E8%B0%83%E5%8F%82)
  - [4.1 å­¦ä¹ ç›®æ ‡](#41-%E5%AD%A6%E4%B9%A0%E7%9B%AE%E6%A0%87)
  - [4.2 å†…å®¹ä»‹ç»](#42-%E5%86%85%E5%AE%B9%E4%BB%8B%E7%BB%8D)
  - [4.3 æ¨¡å‹ç›¸å…³åŸç†ä»‹ç»](#43-%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D)
    - [4.3.1 é€»è¾‘å›å½’æ¨¡å‹](#431-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B)
    - [4.3.2 å†³ç­–æ ‘æ¨¡å‹](#432-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B)
    - [4.3.3 GBDTæ¨¡å‹](#433-gbdt%E6%A8%A1%E5%9E%8B)
    - [4.3.4 XGBoostæ¨¡å‹](#434-xgboost%E6%A8%A1%E5%9E%8B)
    - [4.3.5 LightGBMæ¨¡å‹](#435-lightgbm%E6%A8%A1%E5%9E%8B)
    - [4.3.6 Catboostæ¨¡å‹](#436-catboost%E6%A8%A1%E5%9E%8B)
    - [4.3.7 æ—¶é—´åºåˆ—æ¨¡å‹(é€‰å­¦)](#437-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E9%80%89%E5%AD%A6)
    - [4.3.8 æ¨èæ•™æï¼š](#438-%E6%8E%A8%E8%8D%90%E6%95%99%E6%9D%90)
  - [4.4 æ¨¡å‹å¯¹æ¯”ä¸æ€§èƒ½è¯„ä¼°](#44-%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94%E4%B8%8E%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0)
    - [4.4.1 é€»è¾‘å›å½’](#441-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92)
    - [4.4.2 å†³ç­–æ ‘æ¨¡å‹](#442-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B)
    - [4.4.3 é›†æˆæ¨¡å‹é›†æˆæ–¹æ³•ï¼ˆensemble methodï¼‰](#443-%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95ensemble-method)
    - [4.4.4 æ¨¡å‹è¯„ä¼°æ–¹æ³•](#444-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95)
    - [4.4.5 æ¨¡å‹è¯„ä»·æ ‡å‡†](#445-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86)
  - [4.5 ä»£ç ç¤ºä¾‹](#45-%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B)
    - [4.5.1 å¯¼å…¥ç›¸å…³å…³å’Œç›¸å…³è®¾ç½®](#451-%E5%AF%BC%E5%85%A5%E7%9B%B8%E5%85%B3%E5%85%B3%E5%92%8C%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE)
    - [4.5.2 è¯»å–æ•°æ®](#452-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE)
    - [4.5.3 ç®€å•å»ºæ¨¡](#453-%E7%AE%80%E5%8D%95%E5%BB%BA%E6%A8%A1)
    - [4.5.4 æ¨¡å‹è°ƒå‚](#454-%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82)
  - [4.6 ç»éªŒæ€»ç»“](#46-%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->


# Task4 å»ºæ¨¡ä¸è°ƒå‚

æ­¤éƒ¨åˆ†ä¸ºé›¶åŸºç¡€å…¥é—¨é‡‘èé£æ§çš„ Task4 å»ºæ¨¡è°ƒå‚éƒ¨åˆ†ï¼Œå¸¦ä½ æ¥äº†è§£å„ç§æ¨¡å‹ä»¥åŠæ¨¡å‹çš„è¯„ä»·å’Œè°ƒå‚ç­–ç•¥ï¼Œæ¬¢è¿å¤§å®¶åç»­å¤šå¤šäº¤æµã€‚

èµ›é¢˜ï¼šé›¶åŸºç¡€å…¥é—¨æ•°æ®æŒ–æ˜ - é›¶åŸºç¡€å…¥é—¨é‡‘èé£æ§ä¹‹è´·æ¬¾è¿çº¦é¢„æµ‹

åœ°å€ï¼š https://tianchi.aliyun.com/competition/entrance/531830/introduction



## 4.1 å­¦ä¹ ç›®æ ‡

- å­¦ä¹ åœ¨é‡‘èåˆ†æ§é¢†åŸŸå¸¸ç”¨çš„æœºå™¨å­¦ä¹ æ¨¡å‹
- å­¦ä¹ æœºå™¨å­¦ä¹ æ¨¡å‹çš„å»ºæ¨¡è¿‡ç¨‹ä¸è°ƒå‚æµç¨‹
- å®Œæˆç›¸åº”å­¦ä¹ æ‰“å¡ä»»åŠ¡ 



## 4.2 å†…å®¹ä»‹ç»

- é€»è¾‘å›å½’æ¨¡å‹ï¼š

  - ç†è§£é€»è¾‘å›å½’æ¨¡å‹ï¼›
  - é€»è¾‘å›å½’æ¨¡å‹çš„åº”ç”¨ï¼›
  - é€»è¾‘å›å½’çš„ä¼˜ç¼ºç‚¹ï¼›

- æ ‘æ¨¡å‹ï¼š

  - ç†è§£æ ‘æ¨¡å‹ï¼›
  - æ ‘æ¨¡å‹çš„åº”ç”¨ï¼›
  - æ ‘æ¨¡å‹çš„ä¼˜ç¼ºç‚¹ï¼›

- é›†æˆæ¨¡å‹

  - åŸºäºbaggingæ€æƒ³çš„é›†æˆæ¨¡å‹
    - éšæœºæ£®æ—æ¨¡å‹
  - åŸºäºboostingæ€æƒ³çš„é›†æˆæ¨¡å‹
    - XGBoostæ¨¡å‹
    - LightGBMæ¨¡å‹
    - CatBoostæ¨¡å‹

- æ¨¡å‹å¯¹æ¯”ä¸æ€§èƒ½è¯„ä¼°ï¼š

  - å›å½’æ¨¡å‹/æ ‘æ¨¡å‹/é›†æˆæ¨¡å‹ï¼›
  - æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼›
  - æ¨¡å‹è¯„ä»·ç»“æœï¼›

- æ¨¡å‹è°ƒå‚ï¼š

  - è´ªå¿ƒè°ƒå‚æ–¹æ³•ï¼›

  - ç½‘æ ¼è°ƒå‚æ–¹æ³•ï¼›

  - è´å¶æ–¯è°ƒå‚æ–¹æ³•ï¼› 

    

## 4.3 æ¨¡å‹ç›¸å…³åŸç†ä»‹ç»

ç”±äºç›¸å…³ç®—æ³•åŸç†ç¯‡å¹…è¾ƒé•¿ï¼Œæœ¬æ–‡æ¨èäº†ä¸€äº›åšå®¢ä¸æ•™æä¾›åˆå­¦è€…ä»¬è¿›è¡Œå­¦ä¹ ã€‚

### 4.3.1 é€»è¾‘å›å½’æ¨¡å‹

https://blog.csdn.net/han_xiaoyang/article/details/49123419

### 4.3.2 å†³ç­–æ ‘æ¨¡å‹

https://blog.csdn.net/c406495762/article/details/76262487

### 4.3.3 GBDTæ¨¡å‹

https://zhuanlan.zhihu.com/p/45145899

### 4.3.4 XGBoostæ¨¡å‹

https://blog.csdn.net/wuzhongqiang/article/details/104854890

### 4.3.5 LightGBMæ¨¡å‹

https://blog.csdn.net/wuzhongqiang/article/details/105350579

### 4.3.6 Catboostæ¨¡å‹

https://mp.weixin.qq.com/s/xloTLr5NJBgBspMQtxPoFA

### 4.3.7 æ—¶é—´åºåˆ—æ¨¡å‹(é€‰å­¦)

RNNï¼šhttps://zhuanlan.zhihu.com/p/45289691

LSTMï¼šhttps://zhuanlan.zhihu.com/p/83496936

### 4.3.8 æ¨èæ•™æï¼š

ã€Šæœºå™¨å­¦ä¹ ã€‹ https://book.douban.com/subject/26708119/

ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ https://book.douban.com/subject/10590856/

ã€Šé¢å‘æœºå™¨å­¦ä¹ çš„ç‰¹å¾å·¥ç¨‹ã€‹ https://book.douban.com/subject/26826639/

ã€Šä¿¡ç”¨è¯„åˆ†æ¨¡å‹æŠ€æœ¯ä¸åº”ç”¨ã€‹https://book.douban.com/subject/1488075/

ã€Šæ•°æ®åŒ–é£æ§ã€‹https://book.douban.com/subject/30282558/ 



## 4.4 æ¨¡å‹å¯¹æ¯”ä¸æ€§èƒ½è¯„ä¼°

### 4.4.1 é€»è¾‘å›å½’

- ä¼˜ç‚¹
  - è®­ç»ƒé€Ÿåº¦è¾ƒå¿«ï¼Œåˆ†ç±»çš„æ—¶å€™ï¼Œè®¡ç®—é‡ä»…ä»…åªå’Œç‰¹å¾çš„æ•°ç›®ç›¸å…³ï¼›
  - ç®€å•æ˜“ç†è§£ï¼Œæ¨¡å‹çš„å¯è§£é‡Šæ€§éå¸¸å¥½ï¼Œä»ç‰¹å¾çš„æƒé‡å¯ä»¥çœ‹åˆ°ä¸åŒçš„ç‰¹å¾å¯¹æœ€åç»“æœçš„å½±å“ï¼›
  - é€‚åˆäºŒåˆ†ç±»é—®é¢˜ï¼Œä¸éœ€è¦ç¼©æ”¾è¾“å…¥ç‰¹å¾ï¼›
  - å†…å­˜èµ„æºå ç”¨å°ï¼Œåªéœ€è¦å­˜å‚¨å„ä¸ªç»´åº¦çš„ç‰¹å¾å€¼ï¼›

- ç¼ºç‚¹
  
  - **é€»è¾‘å›å½’éœ€è¦é¢„å…ˆå¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ã€å¯å‚è€ƒtask3ç‰¹å¾å·¥ç¨‹ã€‘ï¼›**
    
  - ä¸èƒ½ç”¨Logisticå›å½’å»è§£å†³éçº¿æ€§é—®é¢˜ï¼Œå› ä¸ºLogisticçš„å†³ç­–é¢æ˜¯çº¿æ€§çš„ï¼›
  
  - å¯¹å¤šé‡å…±çº¿æ€§æ•°æ®è¾ƒä¸ºæ•æ„Ÿï¼Œä¸”å¾ˆéš¾å¤„ç†æ•°æ®ä¸å¹³è¡¡çš„é—®é¢˜ï¼›
  
  - å‡†ç¡®ç‡å¹¶ä¸æ˜¯å¾ˆé«˜ï¼Œå› ä¸ºå½¢å¼éå¸¸ç®€å•ï¼Œå¾ˆéš¾å»æ‹Ÿåˆæ•°æ®çš„çœŸå®åˆ†å¸ƒï¼› 
  
    

### 4.4.2 å†³ç­–æ ‘æ¨¡å‹

- ä¼˜ç‚¹
  - ç®€å•ç›´è§‚ï¼Œç”Ÿæˆçš„å†³ç­–æ ‘å¯ä»¥å¯è§†åŒ–å±•ç¤º
  - **æ•°æ®ä¸éœ€è¦é¢„å¤„ç†ï¼Œä¸éœ€è¦å½’ä¸€åŒ–ï¼Œä¸éœ€è¦å¤„ç†ç¼ºå¤±æ•°æ®**
  - æ—¢å¯ä»¥å¤„ç†ç¦»æ•£å€¼ï¼Œä¹Ÿå¯ä»¥å¤„ç†è¿ç»­å€¼
- ç¼ºç‚¹
  - å†³ç­–æ ‘ç®—æ³•éå¸¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸å¼ºï¼ˆå¯è¿›è¡Œé€‚å½“çš„å‰ªæï¼‰
  - é‡‡ç”¨çš„æ˜¯è´ªå¿ƒç®—æ³•ï¼Œå®¹æ˜“å¾—åˆ°å±€éƒ¨æœ€ä¼˜è§£
  
  

### 4.4.3 é›†æˆæ¨¡å‹é›†æˆæ–¹æ³•ï¼ˆensemble methodï¼‰

é€šè¿‡ç»„åˆå¤šä¸ªå­¦ä¹ å™¨æ¥å®Œæˆå­¦ä¹ ä»»åŠ¡ï¼Œé€šè¿‡é›†æˆæ–¹æ³•ï¼Œå¯ä»¥å°†å¤šä¸ªå¼±å­¦ä¹ å™¨ç»„åˆæˆä¸€ä¸ªå¼ºåˆ†ç±»å™¨ï¼Œå› æ­¤é›†æˆå­¦ä¹ çš„æ³›åŒ–èƒ½åŠ›ä¸€èˆ¬æ¯”å•ä¸€åˆ†ç±»å™¨è¦å¥½ã€‚

é›†æˆæ–¹æ³•ä¸»è¦åŒ…æ‹¬Baggingå’ŒBoostingï¼ŒBaggingå’ŒBoostingéƒ½æ˜¯å°†å·²æœ‰çš„åˆ†ç±»æˆ–å›å½’ç®—æ³•é€šè¿‡ä¸€å®šæ–¹å¼ç»„åˆèµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªæ›´åŠ å¼ºå¤§çš„åˆ†ç±»ã€‚ä¸¤ç§æ–¹æ³•éƒ½æ˜¯æŠŠè‹¥å¹²ä¸ªåˆ†ç±»å™¨æ•´åˆä¸ºä¸€ä¸ªåˆ†ç±»å™¨çš„æ–¹æ³•ï¼Œåªæ˜¯æ•´åˆçš„æ–¹å¼ä¸ä¸€æ ·ï¼Œæœ€ç»ˆå¾—åˆ°ä¸ä¸€æ ·çš„æ•ˆæœã€‚å¸¸è§çš„åŸºäºBagginæ€æƒ³çš„é›†æˆæ¨¡å‹æœ‰ï¼šéšæœºæ£®æ—ã€åŸºäºBoostingæ€æƒ³çš„é›†æˆæ¨¡å‹æœ‰ï¼šAdaboostã€GBDTã€XgBoostã€LightGBMç­‰ã€‚ 

**Bagginå’ŒBoostingçš„åŒºåˆ«æ€»ç»“å¦‚ä¸‹ï¼š**

- **æ ·æœ¬é€‰æ‹©ä¸Šï¼š** Baggingæ–¹æ³•çš„è®­ç»ƒé›†æ˜¯ä»åŸå§‹é›†ä¸­æœ‰æ”¾å›çš„é€‰å–ï¼Œæ‰€ä»¥ä»åŸå§‹é›†ä¸­é€‰å‡ºçš„å„è½®è®­ç»ƒé›†ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼›è€ŒBoostingæ–¹æ³•éœ€è¦æ¯ä¸€è½®çš„è®­ç»ƒé›†ä¸å˜ï¼Œåªæ˜¯è®­ç»ƒé›†ä¸­æ¯ä¸ªæ ·æœ¬åœ¨åˆ†ç±»å™¨ä¸­çš„æƒé‡å‘ç”Ÿå˜åŒ–ã€‚è€Œæƒå€¼æ˜¯æ ¹æ®ä¸Šä¸€è½®çš„åˆ†ç±»ç»“æœè¿›è¡Œè°ƒæ•´
- **æ ·ä¾‹æƒé‡ä¸Šï¼š** Baggingæ–¹æ³•ä½¿ç”¨å‡åŒ€å–æ ·ï¼Œæ‰€ä»¥æ¯ä¸ªæ ·æœ¬çš„æƒé‡ç›¸ç­‰ï¼›è€ŒBoostingæ–¹æ³•æ ¹æ®é”™è¯¯ç‡ä¸æ–­è°ƒæ•´æ ·æœ¬çš„æƒå€¼ï¼Œé”™è¯¯ç‡è¶Šå¤§åˆ™æƒé‡è¶Šå¤§
- **é¢„æµ‹å‡½æ•°ä¸Šï¼š** Baggingæ–¹æ³•ä¸­æ‰€æœ‰é¢„æµ‹å‡½æ•°çš„æƒé‡ç›¸ç­‰ï¼›è€ŒBoostingæ–¹æ³•ä¸­æ¯ä¸ªå¼±åˆ†ç±»å™¨éƒ½æœ‰ç›¸åº”çš„æƒé‡ï¼Œå¯¹äºåˆ†ç±»è¯¯å·®å°çš„åˆ†ç±»å™¨ä¼šæœ‰æ›´å¤§çš„æƒé‡
- **å¹¶è¡Œè®¡ç®—ä¸Šï¼š** Baggingæ–¹æ³•ä¸­å„ä¸ªé¢„æµ‹å‡½æ•°å¯ä»¥å¹¶è¡Œç”Ÿæˆï¼›è€ŒBoostingæ–¹æ³•å„ä¸ªé¢„æµ‹å‡½æ•°åªèƒ½é¡ºåºç”Ÿæˆï¼Œå› ä¸ºåä¸€ä¸ªæ¨¡å‹å‚æ•°éœ€è¦å‰ä¸€è½®æ¨¡å‹çš„ç»“æœã€‚ 



### 4.4.4 æ¨¡å‹è¯„ä¼°æ–¹æ³•

å¯¹äºæ¨¡å‹æ¥è¯´ï¼Œå…¶åœ¨è®­ç»ƒé›†ä¸Šé¢çš„è¯¯å·®æˆ‘ä»¬ç§°ä¹‹ä¸º**è®­ç»ƒè¯¯å·®**æˆ–è€…**ç»éªŒè¯¯å·®**ï¼Œè€Œåœ¨æµ‹è¯•é›†ä¸Šçš„è¯¯å·®ç§°ä¹‹ä¸º**æµ‹è¯•è¯¯å·®**ã€‚

å¯¹äºæˆ‘ä»¬æ¥è¯´ï¼Œæˆ‘ä»¬æ›´å…³å¿ƒçš„æ˜¯æ¨¡å‹å¯¹äºæ–°æ ·æœ¬çš„å­¦ä¹ èƒ½åŠ›ï¼Œå³æˆ‘ä»¬å¸Œæœ›é€šè¿‡å¯¹å·²æœ‰æ ·æœ¬çš„å­¦ä¹ ï¼Œå°½å¯èƒ½çš„å°†æ‰€æœ‰æ½œåœ¨æ ·æœ¬çš„æ™®éè§„å¾‹å­¦åˆ°æ‰‹ï¼Œè€Œå¦‚æœæ¨¡å‹å¯¹è®­ç»ƒæ ·æœ¬å­¦çš„å¤ªå¥½ï¼Œåˆ™æœ‰å¯èƒ½æŠŠè®­ç»ƒæ ·æœ¬è‡ªèº«æ‰€å…·æœ‰çš„ä¸€äº›ç‰¹ç‚¹å½“åšæ‰€æœ‰æ½œåœ¨æ ·æœ¬çš„æ™®éç‰¹ç‚¹ï¼Œè¿™æ—¶å€™æˆ‘ä»¬å°±ä¼šå‡ºç°**è¿‡æ‹Ÿåˆ**çš„é—®é¢˜ã€‚

å› æ­¤æˆ‘ä»¬é€šå¸¸å°†å·²æœ‰çš„æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸¤éƒ¨åˆ†ï¼Œå…¶ä¸­è®­ç»ƒé›†ç”¨æ¥è®­ç»ƒæ¨¡å‹ï¼Œè€Œæµ‹è¯•é›†åˆ™æ˜¯ç”¨æ¥è¯„ä¼°æ¨¡å‹å¯¹äºæ–°æ ·æœ¬çš„åˆ¤åˆ«èƒ½åŠ›ã€‚

**å¯¹äºæ•°æ®é›†çš„åˆ’åˆ†ï¼Œæˆ‘ä»¬é€šå¸¸è¦ä¿è¯æ»¡è¶³ä»¥ä¸‹ä¸¤ä¸ªæ¡ä»¶ï¼š**

- è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åˆ†å¸ƒè¦ä¸æ ·æœ¬çœŸå®åˆ†å¸ƒä¸€è‡´ï¼Œå³è®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ½è¦ä¿è¯æ˜¯ä»æ ·æœ¬çœŸå®åˆ†å¸ƒä¸­ç‹¬ç«‹åŒåˆ†å¸ƒé‡‡æ ·è€Œå¾—ï¼›
- è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¦äº’æ–¥ 

**å¯¹äºæ•°æ®é›†çš„åˆ’åˆ†æœ‰ä¸‰ç§æ–¹æ³•ï¼šç•™å‡ºæ³•ï¼Œäº¤å‰éªŒè¯æ³•å’Œè‡ªåŠ©æ³•ï¼Œä¸‹é¢æŒ¨ä¸ªä»‹ç»ï¼š**

- **â‘ ç•™å‡ºæ³•**

  ç•™å‡ºæ³•æ˜¯ç›´æ¥å°†æ•°æ®é›†Dåˆ’åˆ†ä¸ºä¸¤ä¸ªäº’æ–¥çš„é›†åˆï¼Œå…¶ä¸­ä¸€ä¸ªé›†åˆä½œä¸ºè®­ç»ƒé›†Sï¼Œå¦ä¸€ä¸ªä½œä¸ºæµ‹è¯•é›†Tã€‚éœ€è¦æ³¨æ„çš„æ˜¯åœ¨åˆ’åˆ†çš„æ—¶å€™è¦å°½å¯èƒ½ä¿è¯æ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ï¼Œå³é¿å…å› æ•°æ®åˆ’åˆ†è¿‡ç¨‹å¼•å…¥é¢å¤–çš„åå·®è€Œå¯¹æœ€ç»ˆç»“æœäº§ç”Ÿå½±å“ã€‚ä¸ºäº†ä¿è¯æ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ï¼Œé€šå¸¸æˆ‘ä»¬é‡‡ç”¨**åˆ†å±‚é‡‡æ ·**çš„æ–¹å¼æ¥å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ã€‚

  **Tipsï¼š** é€šå¸¸ï¼Œä¼šå°†æ•°æ®é›†Dä¸­å¤§çº¦2/3~4/5çš„æ ·æœ¬ä½œä¸ºè®­ç»ƒé›†ï¼Œå…¶ä½™çš„ä½œä¸ºæµ‹è¯•é›†ã€‚ 

- **â‘¡äº¤å‰éªŒè¯æ³•**

  **kæŠ˜äº¤å‰éªŒè¯**é€šå¸¸å°†æ•°æ®é›†Dåˆ†ä¸ºkä»½ï¼Œå…¶ä¸­k-1ä»½ä½œä¸ºè®­ç»ƒé›†ï¼Œå‰©ä½™çš„ä¸€ä»½ä½œä¸ºæµ‹è¯•é›†ï¼Œè¿™æ ·å°±å¯ä»¥è·å¾—kç»„è®­ç»ƒ/æµ‹è¯•é›†ï¼Œå¯ä»¥è¿›è¡Œkæ¬¡è®­ç»ƒä¸æµ‹è¯•ï¼Œæœ€ç»ˆè¿”å›çš„æ˜¯kä¸ªæµ‹è¯•ç»“æœçš„å‡å€¼ã€‚äº¤å‰éªŒè¯ä¸­æ•°æ®é›†çš„åˆ’åˆ†ä¾ç„¶æ˜¯ä¾æ®**åˆ†å±‚é‡‡æ ·**çš„æ–¹å¼æ¥è¿›è¡Œã€‚

  å¯¹äºäº¤å‰éªŒè¯æ³•ï¼Œå…¶kå€¼çš„é€‰å–å¾€å¾€å†³å®šäº†è¯„ä¼°ç»“æœçš„ç¨³å®šæ€§å’Œä¿çœŸæ€§ï¼Œ**é€šå¸¸kå€¼é€‰å–10ã€‚**

  å½“k=1çš„æ—¶å€™ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º**ç•™ä¸€æ³•**

- **â‘¢è‡ªåŠ©æ³•**

  æˆ‘ä»¬æ¯æ¬¡ä»æ•°æ®é›†Dä¸­å–ä¸€ä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†ä¸­çš„å…ƒç´ ï¼Œç„¶åæŠŠè¯¥æ ·æœ¬æ”¾å›ï¼Œé‡å¤è¯¥è¡Œä¸ºmæ¬¡ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°å¤§å°ä¸ºmçš„è®­ç»ƒé›†ï¼Œåœ¨è¿™é‡Œé¢æœ‰çš„æ ·æœ¬é‡å¤å‡ºç°ï¼Œæœ‰çš„æ ·æœ¬åˆ™æ²¡æœ‰å‡ºç°è¿‡ï¼Œæˆ‘ä»¬æŠŠé‚£äº›æ²¡æœ‰å‡ºç°è¿‡çš„æ ·æœ¬ä½œä¸ºæµ‹è¯•é›†ã€‚

  è¿›è¡Œè¿™æ ·é‡‡æ ·çš„åŸå› æ˜¯å› ä¸ºåœ¨Dä¸­çº¦æœ‰36.8%çš„æ•°æ®æ²¡æœ‰åœ¨è®­ç»ƒé›†ä¸­å‡ºç°è¿‡ã€‚ç•™å‡ºæ³•ä¸äº¤å‰éªŒè¯æ³•éƒ½æ˜¯ä½¿ç”¨**åˆ†å±‚é‡‡æ ·**çš„æ–¹å¼è¿›è¡Œæ•°æ®é‡‡æ ·ä¸åˆ’åˆ†ï¼Œè€Œè‡ªåŠ©æ³•åˆ™æ˜¯ä½¿ç”¨**æœ‰æ”¾å›é‡å¤é‡‡æ ·**çš„æ–¹å¼è¿›è¡Œæ•°æ®é‡‡æ ·

**æ•°æ®é›†åˆ’åˆ†æ€»ç»“**

- å¯¹äºæ•°æ®é‡å……è¶³çš„æ—¶å€™ï¼Œé€šå¸¸é‡‡ç”¨**ç•™å‡ºæ³•**æˆ–è€…**kæŠ˜äº¤å‰éªŒè¯æ³•**æ¥è¿›è¡Œè®­ç»ƒ/æµ‹è¯•é›†çš„åˆ’åˆ†ï¼›
- å¯¹äºæ•°æ®é›†å°ä¸”éš¾ä»¥æœ‰æ•ˆåˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†æ—¶ä½¿ç”¨**è‡ªåŠ©æ³•**ï¼›
- å¯¹äºæ•°æ®é›†å°ä¸”å¯æœ‰æ•ˆåˆ’åˆ†çš„æ—¶å€™æœ€å¥½ä½¿ç”¨**ç•™ä¸€æ³•**æ¥è¿›è¡Œåˆ’åˆ†ï¼Œå› ä¸ºè¿™ç§æ–¹æ³•æœ€ä¸ºå‡†ç¡® 



### 4.4.5 æ¨¡å‹è¯„ä»·æ ‡å‡†

å¯¹äºæœ¬æ¬¡æ¯”èµ›ï¼Œæˆ‘ä»¬é€‰ç”¨aucä½œä¸ºæ¨¡å‹è¯„ä»·æ ‡å‡†ï¼Œç±»ä¼¼çš„è¯„ä»·æ ‡å‡†è¿˜æœ‰ksã€f1-scoreç­‰ï¼Œå…·ä½“ä»‹ç»ä¸å®ç°å¤§å®¶å¯ä»¥å›é¡¾ä¸‹task1ä¸­çš„å†…å®¹ã€‚

 **ä¸€èµ·æ¥çœ‹ä¸€ä¸‹aucåˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ**

åœ¨é€»è¾‘å›å½’é‡Œé¢ï¼Œå¯¹äºæ­£è´Ÿä¾‹çš„ç•Œå®šï¼Œé€šå¸¸ä¼šè®¾ä¸€ä¸ªé˜ˆå€¼ï¼Œå¤§äºé˜ˆå€¼çš„ä¸ºæ­£ç±»ï¼Œå°äºé˜ˆå€¼ä¸ºè´Ÿç±»ã€‚å¦‚æœæˆ‘ä»¬å‡å°è¿™ä¸ªé˜€å€¼ï¼Œæ›´å¤šçš„æ ·æœ¬ä¼šè¢«è¯†åˆ«ä¸ºæ­£ç±»ï¼Œæé«˜æ­£ç±»çš„è¯†åˆ«ç‡ï¼Œä½†åŒæ—¶ä¹Ÿä¼šä½¿å¾—æ›´å¤šçš„è´Ÿç±»è¢«é”™è¯¯è¯†åˆ«ä¸ºæ­£ç±»ã€‚ä¸ºäº†ç›´è§‚è¡¨ç¤ºè¿™ä¸€ç°è±¡ï¼Œå¼•å…¥ROCã€‚

æ ¹æ®åˆ†ç±»ç»“æœè®¡ç®—å¾—åˆ°ROCç©ºé—´ä¸­ç›¸åº”çš„ç‚¹ï¼Œè¿æ¥è¿™äº›ç‚¹å°±å½¢æˆROC curveï¼Œæ¨ªåæ ‡ä¸ºFalse Positive Rate(FPRï¼šå‡æ­£ç‡)ï¼Œçºµåæ ‡ä¸ºTrue Positive Rate(TPRï¼šçœŸæ­£ç‡)ã€‚ ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œè¿™ä¸ªæ›²çº¿éƒ½åº”è¯¥å¤„äº(0,0)å’Œ(1,1)è¿çº¿çš„ä¸Šæ–¹,å¦‚å›¾ï¼š 

![ROC&AUC.png](https://img-blog.csdnimg.cn/20200905094903724.png)   


ROCæ›²çº¿ä¸­çš„å››ä¸ªç‚¹ï¼š

- ç‚¹(0,1)ï¼šå³FPR=0, TPR=1ï¼Œæ„å‘³ç€FNï¼0ä¸”FPï¼0ï¼Œå°†æ‰€æœ‰çš„æ ·æœ¬éƒ½æ­£ç¡®åˆ†ç±»ï¼›
- ç‚¹(1,0)ï¼šå³FPR=1ï¼ŒTPR=0ï¼Œæœ€å·®åˆ†ç±»å™¨ï¼Œé¿å¼€äº†æ‰€æœ‰æ­£ç¡®ç­”æ¡ˆï¼›
- ç‚¹(0,0)ï¼šå³FPR=TPR=0ï¼ŒFPï¼TPï¼0ï¼Œåˆ†ç±»å™¨æŠŠæ¯ä¸ªå®ä¾‹éƒ½é¢„æµ‹ä¸ºè´Ÿç±»ï¼›
- ç‚¹(1,1)ï¼šåˆ†ç±»å™¨æŠŠæ¯ä¸ªå®ä¾‹éƒ½é¢„æµ‹ä¸ºæ­£ç±» 

æ€»ä¹‹ï¼šROCæ›²çº¿è¶Šæ¥è¿‘å·¦ä¸Šè§’ï¼Œè¯¥åˆ†ç±»å™¨çš„æ€§èƒ½è¶Šå¥½ï¼Œå…¶æ³›åŒ–æ€§èƒ½å°±è¶Šå¥½ã€‚è€Œä¸”ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœROCæ˜¯å…‰æ»‘çš„ï¼Œé‚£ä¹ˆåŸºæœ¬å¯ä»¥åˆ¤æ–­æ²¡æœ‰å¤ªå¤§çš„overfittingã€‚

**ä½†æ˜¯å¯¹äºä¸¤ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬å¦‚ä½•åˆ¤æ–­å“ªä¸ªæ¨¡å‹çš„æ³›åŒ–æ€§èƒ½æ›´ä¼˜å‘¢ï¼Ÿè¿™é‡Œæˆ‘ä»¬æœ‰ä¸»è¦ä»¥ä¸‹ä¸¤ç§æ–¹æ³•ï¼š**

å¦‚æœæ¨¡å‹Açš„ROCæ›²çº¿å®Œå…¨åŒ…ä½äº†æ¨¡å‹Bçš„ROCæ›²çº¿ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±è®¤ä¸ºæ¨¡å‹Aè¦ä¼˜äºæ¨¡å‹Bï¼›

å¦‚æœä¸¤æ¡æ›²çº¿æœ‰äº¤å‰çš„è¯ï¼Œæˆ‘ä»¬å°±é€šè¿‡æ¯”è¾ƒROCä¸Xï¼ŒYè½´æ‰€å›´å¾—æ›²çº¿çš„é¢ç§¯æ¥åˆ¤æ–­ï¼Œé¢ç§¯è¶Šå¤§ï¼Œæ¨¡å‹çš„æ€§èƒ½å°±è¶Šä¼˜ï¼Œ**è¿™ä¸ªé¢ç§¯æˆ‘ä»¬ç§°ä¹‹ä¸ºAUC(area under ROC curve)** 



## 4.5 ä»£ç ç¤ºä¾‹

### 4.5.1 å¯¼å…¥ç›¸å…³å…³å’Œç›¸å…³è®¾ç½®

```python
import pandas as pd
import numpy as np
import warnings
import os
import seaborn as sns
import matplotlib.pyplot as plt
"""
sns ç›¸å…³è®¾ç½®
@return:
"""
# å£°æ˜ä½¿ç”¨ Seaborn æ ·å¼
sns.set()
# æœ‰äº”ç§seabornçš„ç»˜å›¾é£æ ¼ï¼Œå®ƒä»¬åˆ†åˆ«æ˜¯ï¼šdarkgrid, whitegrid, dark, white, ticksã€‚é»˜è®¤çš„ä¸»é¢˜æ˜¯darkgridã€‚
sns.set_style("whitegrid")
# æœ‰å››ä¸ªé¢„ç½®çš„ç¯å¢ƒï¼ŒæŒ‰å¤§å°ä»å°åˆ°å¤§æ’åˆ—åˆ†åˆ«ä¸ºï¼špaper, notebook, talk, posterã€‚å…¶ä¸­ï¼Œnotebookæ˜¯é»˜è®¤çš„ã€‚
sns.set_context('talk')
# ä¸­æ–‡å­—ä½“è®¾ç½®-é»‘ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
# è§£å†³ä¿å­˜å›¾åƒæ˜¯è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
plt.rcParams['axes.unicode_minus'] = False
# è§£å†³Seabornä¸­æ–‡æ˜¾ç¤ºé—®é¢˜å¹¶è°ƒæ•´å­—ä½“å¤§å°
sns.set(font='SimHei')
```

### 4.5.2 è¯»å–æ•°æ®

reduce_mem_usage å‡½æ•°é€šè¿‡è°ƒæ•´æ•°æ®ç±»å‹ï¼Œå¸®åŠ©æˆ‘ä»¬å‡å°‘æ•°æ®åœ¨å†…å­˜ä¸­å ç”¨çš„ç©ºé—´

```python
def reduce_mem_usage(df):
    start_mem = df.memory_usage().sum() 
    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))
    
    for col in df.columns:
        col_type = df[col].dtype
        
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
        else:
            df[col] = df[col].astype('category')

    end_mem = df.memory_usage().sum() 
    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))
    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))
    
    return df
```

```python
# è¯»å–æ•°æ®
data = pd.read_csv('dataset/data_for_model.csv')
data = reduce_mem_usage(data)
```

```
Memory usage of dataframe is 928000128.00 MB
Memory usage after optimization is: 165006456.00 MB
Decreased by 82.2%
```

### 4.5.3 ç®€å•å»ºæ¨¡

> Tips1ï¼šé‡‘èé£æ§çš„å®é™…é¡¹ç›®å¤šæ¶‰åŠåˆ°ä¿¡ç”¨è¯„åˆ†ï¼Œå› æ­¤éœ€è¦æ¨¡å‹ç‰¹å¾å…·æœ‰è¾ƒå¥½çš„å¯è§£é‡Šæ€§ï¼Œæ‰€ä»¥ç›®å‰åœ¨å®é™…é¡¹ç›®ä¸­å¤šè¿˜æ˜¯ä»¥é€»è¾‘å›å½’ä½œä¸ºåŸºç¡€æ¨¡å‹ã€‚ä½†æ˜¯åœ¨æ¯”èµ›ä¸­ä»¥å¾—åˆ†é«˜ä½ä¸ºå‡†ï¼Œä¸éœ€è¦ä¸¥è°¨çš„å¯è§£é‡Šæ€§ï¼Œæ‰€ä»¥å¤§å¤šåŸºäºé›†æˆç®—æ³•è¿›è¡Œå»ºæ¨¡ã€‚
>
> Tips2ï¼šå› ä¸ºé€»è¾‘å›å½’çš„ç®—æ³•ç‰¹æ€§ï¼Œéœ€è¦æå‰å¯¹å¼‚å¸¸å€¼ã€ç¼ºå¤±å€¼æ•°æ®è¿›è¡Œå¤„ç†ã€å‚è€ƒtask3éƒ¨åˆ†ã€‘
>
> Tips3ï¼šåŸºäºæ ‘æ¨¡å‹çš„ç®—æ³•ç‰¹æ€§ï¼Œå¼‚å¸¸å€¼ã€ç¼ºå¤±å€¼å¤„ç†å¯ä»¥è·³è¿‡ï¼Œä½†æ˜¯å¯¹äºä¸šåŠ¡è¾ƒä¸ºäº†è§£çš„åŒå­¦ä¹Ÿå¯ä»¥è‡ªå·±å¯¹ç¼ºå¤±å¼‚å¸¸å€¼è¿›è¡Œå¤„ç†ï¼Œæ•ˆæœå¯èƒ½ä¼šæ›´ä¼˜äºæ¨¡å‹å¤„ç†çš„ç»“æœã€‚
>
> æ³¨ï¼šä»¥ä¸‹å»ºæ¨¡çš„æºæ•°æ®å‚è€ƒbaselineè¿›è¡Œäº†ç›¸åº”çš„ç‰¹å¾å·¥ç¨‹ï¼Œå¯¹äºå¼‚å¸¸ç¼ºå¤±å€¼æœªè¿›è¡Œç›¸åº”çš„å¤„ç†æ“ä½œã€‚

å»ºæ¨¡ä¹‹å‰çš„é¢„æ“ä½œ

```python
from sklearn.model_selection import KFold
# åˆ†ç¦»æ•°æ®é›†ï¼Œæ–¹ä¾¿è¿›è¡Œäº¤å‰éªŒè¯
X_train = data.loc[data['sample']=='train', :].drop(['id','issueDate','isDefault', 'sample'], axis=1)
X_test = data.loc[data['sample']=='test', :].drop(['id','issueDate','isDefault', 'sample'], axis=1)
y_train = data.loc[data['sample']=='train', 'isDefault']

# 5æŠ˜äº¤å‰éªŒè¯
folds = 5
seed = 2020
kf = KFold(n_splits=folds, shuffle=True, random_state=seed)
```

ä½¿ç”¨Lightgbmè¿›è¡Œå»ºæ¨¡

```python
"""å¯¹è®­ç»ƒé›†æ•°æ®è¿›è¡Œåˆ’åˆ†ï¼Œåˆ†æˆè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶è¿›è¡Œç›¸åº”çš„æ“ä½œ"""
from sklearn.model_selection import train_test_split
import lightgbm as lgb
# æ•°æ®é›†åˆ’åˆ†
X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2)
train_matrix = lgb.Dataset(X_train_split, label=y_train_split)
valid_matrix = lgb.Dataset(X_val, label=y_val)

params = {
            'boosting_type': 'gbdt',
            'objective': 'binary',
            'learning_rate': 0.1,
            'metric': 'auc',
            'min_child_weight': 1e-3,
            'num_leaves': 31,
            'max_depth': -1,
            'reg_lambda': 0,
            'reg_alpha': 0,
            'feature_fraction': 1,
            'bagging_fraction': 1,
            'bagging_freq': 0,
            'seed': 2020,
            'nthread': 8,
            'silent': True,
            'verbose': -1,
}

"""ä½¿ç”¨è®­ç»ƒé›†æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒ"""
model = lgb.train(params, train_set=train_matrix, valid_sets=valid_matrix, num_boost_round=20000, verbose_eval=1000, early_stopping_rounds=200)
```

```
Training until validation scores don't improve for 200 rounds
Early stopping, best iteration is:
[427]	valid_0's auc: 0.724947
```

å¯¹éªŒè¯é›†è¿›è¡Œé¢„æµ‹

```python
from sklearn import metrics
from sklearn.metrics import roc_auc_score

"""é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
val_pre_lgb = model.predict(X_val, num_iteration=model.best_iteration)
fpr, tpr, threshold = metrics.roc_curve(y_val, val_pre_lgb)
roc_auc = metrics.auc(fpr, tpr)
print('æœªè°ƒå‚å‰lightgbmå•æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„AUCï¼š{}'.format(roc_auc))
"""ç”»å‡ºrocæ›²çº¿å›¾"""
plt.figure(figsize=(8, 8))
plt.title('Validation ROC')
plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)
plt.ylim(0,1)
plt.xlim(0,1)
plt.legend(loc='best')
plt.title('ROC')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
# ç”»å‡ºå¯¹è§’çº¿
plt.plot([0,1],[0,1],'r--')
plt.show()
```

```
æœªè°ƒå‚å‰lightgbmå•æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„AUCï¼š0.7249469360631181
```

![output_10_1.png](https://img-blog.csdnimg.cn/20200905094420649.png)

æ›´è¿›ä¸€æ­¥çš„ï¼Œä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯è¿›è¡Œæ¨¡å‹æ€§èƒ½è¯„ä¼°

```python
import lightgbm as lgb
"""ä½¿ç”¨lightgbm 5æŠ˜äº¤å‰éªŒè¯è¿›è¡Œå»ºæ¨¡é¢„æµ‹"""
cv_scores = []
for i, (train_index, valid_index) in enumerate(kf.split(X_train, y_train)):
    print('************************************ {} ************************************'.format(str(i+1)))
    X_train_split, y_train_split, X_val, y_val = X_train.iloc[train_index], y_train[train_index], X_train.iloc[valid_index], y_train[valid_index]
    
    train_matrix = lgb.Dataset(X_train_split, label=y_train_split)
    valid_matrix = lgb.Dataset(X_val, label=y_val)

    params = {
                'boosting_type': 'gbdt',
                'objective': 'binary',
                'learning_rate': 0.1,
                'metric': 'auc',
        
                'min_child_weight': 1e-3,
                'num_leaves': 31,
                'max_depth': -1,
                'reg_lambda': 0,
                'reg_alpha': 0,
                'feature_fraction': 1,
                'bagging_fraction': 1,
                'bagging_freq': 0,
                'seed': 2020,
                'nthread': 8,
                'silent': True,
                'verbose': -1,
    }
    
    model = lgb.train(params, train_set=train_matrix, num_boost_round=20000, valid_sets=valid_matrix, verbose_eval=1000, early_stopping_rounds=200)
    val_pred = model.predict(X_val, num_iteration=model.best_iteration)
    
    cv_scores.append(roc_auc_score(y_val, val_pred))
    print(cv_scores)

print("lgb_scotrainre_list:{}".format(cv_scores))
print("lgb_score_mean:{}".format(np.mean(cv_scores)))
print("lgb_score_std:{}".format(np.std(cv_scores)))
```

```
...
lgb_scotrainre_list:[0.7303837315833632, 0.7258692125145638, 0.7305149209921737, 0.7296117869375041, 0.7294438695369077]
lgb_score_mean:0.7291647043129024
lgb_score_std:0.0016998349834934656
```

### 4.5.4 æ¨¡å‹è°ƒå‚

- **1. è´ªå¿ƒè°ƒå‚**

  å…ˆä½¿ç”¨å½“å‰å¯¹æ¨¡å‹å½±å“æœ€å¤§çš„å‚æ•°è¿›è¡Œè°ƒä¼˜ï¼Œè¾¾åˆ°å½“å‰å‚æ•°ä¸‹çš„æ¨¡å‹æœ€ä¼˜åŒ–ï¼Œå†ä½¿ç”¨å¯¹æ¨¡å‹å½±å“æ¬¡ä¹‹çš„å‚æ•°è¿›è¡Œè°ƒä¼˜ï¼Œå¦‚æ­¤ä¸‹å»ï¼Œç›´åˆ°æ‰€æœ‰çš„å‚æ•°è°ƒæ•´å®Œæ¯•ã€‚

  è¿™ä¸ªæ–¹æ³•çš„ç¼ºç‚¹å°±æ˜¯å¯èƒ½ä¼šè°ƒåˆ°å±€éƒ¨æœ€ä¼˜è€Œä¸æ˜¯å…¨å±€æœ€ä¼˜ï¼Œä½†æ˜¯åªéœ€è¦ä¸€æ­¥ä¸€æ­¥çš„è¿›è¡Œå‚æ•°æœ€ä¼˜åŒ–è°ƒè¯•å³å¯ï¼Œå®¹æ˜“ç†è§£ã€‚

  éœ€è¦æ³¨æ„çš„æ˜¯åœ¨æ ‘æ¨¡å‹ä¸­å‚æ•°è°ƒæ•´çš„é¡ºåºï¼Œä¹Ÿå°±æ˜¯å„ä¸ªå‚æ•°å¯¹æ¨¡å‹çš„å½±å“ç¨‹åº¦ï¼Œè¿™é‡Œåˆ—ä¸¾ä¸€ä¸‹æ—¥å¸¸è°ƒå‚è¿‡ç¨‹ä¸­å¸¸ç”¨çš„å‚æ•°å’Œè°ƒå‚é¡ºåºï¼š

  - â‘ ï¼šmax_depthã€num_leaves
  - â‘¡ï¼šmin_data_in_leafã€min_child_weight
  - â‘¢ï¼šbagging_fractionã€ feature_fractionã€bagging_freq
  - â‘£ï¼šreg_lambdaã€reg_alpha
  - â‘¤ï¼šmin_split_gain

  ```python
  from sklearn.model_selection import cross_val_score
  
  # è°ƒobjective
  best_obj = dict()
  for obj in objective:
      model = LGBMRegressor(objective=obj)
      """é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
      score = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
      best_obj[obj] = score
      
  # num_leaves
  best_leaves = dict()
  for leaves in num_leaves:
      model = LGBMRegressor(objective=min(best_obj.items(), key=lambda x:x[1])[0], num_leaves=leaves)
      """é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
      score = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
      best_leaves[leaves] = score
      
  # max_depth
  best_depth = dict()
  for depth in max_depth:
      model = LGBMRegressor(objective=min(best_obj.items(), key=lambda x:x[1])[0],
                            num_leaves=min(best_leaves.items(), key=lambda x:x[1])[0],
                            max_depth=depth)
      """é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
      score = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
      best_depth[depth] = score
  
  """
  å¯ä¾æ¬¡å°†æ¨¡å‹çš„å‚æ•°é€šè¿‡ä¸Šé¢çš„æ–¹å¼è¿›è¡Œè°ƒæ•´ä¼˜åŒ–ï¼Œå¹¶ä¸”é€šè¿‡å¯è§†åŒ–è§‚å¯Ÿåœ¨æ¯ä¸€ä¸ªæœ€ä¼˜å‚æ•°ä¸‹æ¨¡å‹çš„å¾—åˆ†æƒ…å†µ
  """
  ```

  å¯ä¾æ¬¡å°†æ¨¡å‹çš„å‚æ•°é€šè¿‡ä¸Šé¢çš„æ–¹å¼è¿›è¡Œè°ƒæ•´ä¼˜åŒ–ï¼Œå¹¶ä¸”é€šè¿‡å¯è§†åŒ–è§‚å¯Ÿåœ¨æ¯ä¸€ä¸ªæœ€ä¼˜å‚æ•°ä¸‹æ¨¡å‹çš„å¾—åˆ†æƒ…å†µ

- **2. ç½‘æ ¼æœç´¢**

  sklearn æä¾›GridSearchCVç”¨äºè¿›è¡Œç½‘æ ¼æœç´¢ï¼Œåªéœ€è¦æŠŠæ¨¡å‹çš„å‚æ•°è¾“è¿›å»ï¼Œå°±èƒ½ç»™å‡ºæœ€ä¼˜åŒ–çš„ç»“æœå’Œå‚æ•°ã€‚ç›¸æ¯”èµ·è´ªå¿ƒè°ƒå‚ï¼Œç½‘æ ¼æœç´¢çš„ç»“æœä¼šæ›´ä¼˜ï¼Œä½†æ˜¯ç½‘æ ¼æœç´¢åªé€‚åˆäºå°æ•°æ®é›†ï¼Œä¸€æ—¦æ•°æ®çš„é‡çº§ä¸Šå»äº†ï¼Œå¾ˆéš¾å¾—å‡ºç»“æœã€‚

  åŒæ ·ä»¥Lightgbmç®—æ³•ä¸ºä¾‹ï¼Œè¿›è¡Œç½‘æ ¼æœç´¢è°ƒå‚ï¼š

  ```python
  """é€šè¿‡ç½‘æ ¼æœç´¢ç¡®å®šæœ€ä¼˜å‚æ•°"""
  from sklearn.model_selection import GridSearchCV
  
  def get_best_cv_params(learning_rate=0.1, n_estimators=581, num_leaves=31, max_depth=-1, bagging_fraction=1.0, 
                         feature_fraction=1.0, bagging_freq=0, min_data_in_leaf=20, min_child_weight=0.001, 
                         min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=None):
      # è®¾ç½®5æŠ˜äº¤å‰éªŒè¯
      cv_fold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True, )
      
      model_lgb = lgb.LGBMClassifier(learning_rate=learning_rate,
                                     n_estimators=n_estimators,
                                     num_leaves=num_leaves,
                                     max_depth=max_depth,
                                     bagging_fraction=bagging_fraction,
                                     feature_fraction=feature_fraction,
                                     bagging_freq=bagging_freq,
                                     min_data_in_leaf=min_data_in_leaf,
                                     min_child_weight=min_child_weight,
                                     min_split_gain=min_split_gain,
                                     reg_lambda=reg_lambda,
                                     reg_alpha=reg_alpha,
                                     n_jobs= 8
                                    )
      grid_search = GridSearchCV(estimator=model_lgb, 
                                 cv=cv_fold,
                                 param_grid=param_grid,
                                 scoring='roc_auc'
                                )
      grid_search.fit(X_train, y_train)
  
      print('æ¨¡å‹å½“å‰æœ€ä¼˜å‚æ•°ä¸º:{}'.format(grid_search.best_params_))
      print('æ¨¡å‹å½“å‰æœ€ä¼˜å¾—åˆ†ä¸º:{}'.format(grid_search.best_score_))
  ```

  ```python
  """ä»¥ä¸‹ä»£ç æœªè¿è¡Œï¼Œè€—æ—¶è¾ƒé•¿ï¼Œè¯·è°¨æ…è¿è¡Œï¼Œä¸”æ¯ä¸€æ­¥çš„æœ€ä¼˜å‚æ•°éœ€è¦åœ¨ä¸‹ä¸€æ­¥è¿›è¡Œæ‰‹åŠ¨æ›´æ–°ï¼Œè¯·æ³¨æ„"""
  
  """
  éœ€è¦æ³¨æ„ä¸€ä¸‹çš„æ˜¯ï¼Œé™¤äº†è·å–ä¸Šé¢çš„è·å–num_boost_roundæ—¶å€™ç”¨çš„æ˜¯åŸç”Ÿçš„lightgbmï¼ˆå› ä¸ºè¦ç”¨è‡ªå¸¦çš„cvï¼‰
  ä¸‹é¢é…åˆGridSearchCVæ—¶å¿…é¡»ä½¿ç”¨sklearnæ¥å£çš„lightgbmã€‚
  """
  """è®¾ç½®n_estimators ä¸º581ï¼Œè°ƒæ•´num_leaveså’Œmax_depthï¼Œè¿™é‡Œé€‰æ‹©å…ˆç²—è°ƒå†ç»†è°ƒ"""
  lgb_params = {'num_leaves': range(10, 80, 5), 'max_depth': range(3,10,2)}
  get_best_cv_params(learning_rate=0.1, n_estimators=581, num_leaves=None, max_depth=None, min_data_in_leaf=20, 
                     min_child_weight=0.001,bagging_fraction=1.0, feature_fraction=1.0, bagging_freq=0, 
                     min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)
  
  """num_leavesä¸º30ï¼Œmax_depthä¸º7ï¼Œè¿›ä¸€æ­¥ç»†è°ƒnum_leaveså’Œmax_depth"""
  lgb_params = {'num_leaves': range(25, 35, 1), 'max_depth': range(5,9,1)}
  get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=None, max_depth=None, min_data_in_leaf=20, 
                     min_child_weight=0.001,bagging_fraction=1.0, feature_fraction=1.0, bagging_freq=0, 
                     min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)
  
  """
  ç¡®å®šmin_data_in_leafä¸º45ï¼Œmin_child_weightä¸º0.001 ï¼Œä¸‹é¢è¿›è¡Œbagging_fractionã€feature_fractionå’Œbagging_freqçš„è°ƒå‚
  """
  lgb_params = {'bagging_fraction': [i/10 for i in range(5,10,1)], 
                'feature_fraction': [i/10 for i in range(5,10,1)],
                'bagging_freq': range(0,81,10)
               }
  get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=29, max_depth=7, min_data_in_leaf=45, 
                     min_child_weight=0.001,bagging_fraction=None, feature_fraction=None, bagging_freq=None, 
                     min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)
  
  """
  ç¡®å®šbagging_fractionä¸º0.4ã€feature_fractionä¸º0.6ã€bagging_freqä¸º ï¼Œä¸‹é¢è¿›è¡Œreg_lambdaã€reg_alphaçš„è°ƒå‚
  """
  lgb_params = {'reg_lambda': [0,0.001,0.01,0.03,0.08,0.3,0.5], 'reg_alpha': [0,0.001,0.01,0.03,0.08,0.3,0.5]}
  get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=29, max_depth=7, min_data_in_leaf=45, 
                     min_child_weight=0.001,bagging_fraction=0.9, feature_fraction=0.9, bagging_freq=40, 
                     min_split_gain=0, reg_lambda=None, reg_alpha=None, param_grid=lgb_params)
  
  """
  ç¡®å®šreg_lambdaã€reg_alphaéƒ½ä¸º0ï¼Œä¸‹é¢è¿›è¡Œmin_split_gainçš„è°ƒå‚
  """
  lgb_params = {'min_split_gain': [i/10 for i in range(0,11,1)]}
  get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=29, max_depth=7, min_data_in_leaf=45, 
                     min_child_weight=0.001,bagging_fraction=0.9, feature_fraction=0.9, bagging_freq=40, 
                     min_split_gain=None, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)
  ```

  ```python
  """
  å‚æ•°ç¡®å®šå¥½äº†ä»¥åï¼Œæˆ‘ä»¬è®¾ç½®ä¸€ä¸ªæ¯”è¾ƒå°çš„learning_rate 0.005ï¼Œæ¥ç¡®å®šæœ€ç»ˆçš„num_boost_round
  """
  # è®¾ç½®5æŠ˜äº¤å‰éªŒè¯
  # cv_fold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True, )
  final_params = {
                  'boosting_type': 'gbdt',
                  'learning_rate': 0.01,
                  'num_leaves': 29,
                  'max_depth': 7,
                  'min_data_in_leaf':45,
                  'min_child_weight':0.001,
                  'bagging_fraction': 0.9,
                  'feature_fraction': 0.9,
                  'bagging_freq': 40,
                  'min_split_gain': 0,
                  'reg_lambda':0,
                  'reg_alpha':0,
                  'nthread': 6
                 }
  
  cv_result = lgb.cv(train_set=lgb_train,
                     early_stopping_rounds=20,
                     num_boost_round=5000,
                     nfold=5,
                     stratified=True,
                     shuffle=True,
                     params=final_params,
                     metrics='auc',
                     seed=0,
                    )
  
  print('è¿­ä»£æ¬¡æ•°{}'.format(len(cv_result['auc-mean'])))
  print('äº¤å‰éªŒè¯çš„AUCä¸º{}'.format(max(cv_result['auc-mean'])))
  ```

  åœ¨å®é™…è°ƒæ•´è¿‡ç¨‹ä¸­ï¼Œå¯å…ˆè®¾ç½®ä¸€ä¸ªè¾ƒå¤§çš„å­¦ä¹ ç‡ï¼ˆä¸Šé¢çš„ä¾‹å­ä¸­0.1ï¼‰ï¼Œé€šè¿‡LgbåŸç”Ÿçš„cvå‡½æ•°è¿›è¡Œæ ‘ä¸ªæ•°çš„ç¡®å®šï¼Œä¹‹åå†é€šè¿‡ä¸Šé¢çš„å®ä¾‹ä»£ç è¿›è¡Œå‚æ•°çš„è°ƒæ•´ä¼˜åŒ–ã€‚

  æœ€åé’ˆå¯¹æœ€ä¼˜çš„å‚æ•°è®¾ç½®ä¸€ä¸ªè¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆä¾‹å¦‚0.05ï¼‰ï¼ŒåŒæ ·é€šè¿‡cvå‡½æ•°ç¡®å®šæ ‘çš„ä¸ªæ•°ï¼Œç¡®å®šæœ€ç»ˆçš„å‚æ•°ã€‚

  éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé’ˆå¯¹å¤§æ•°æ®é›†ï¼Œä¸Šé¢æ¯ä¸€å±‚å‚æ•°çš„è°ƒæ•´éƒ½éœ€è¦è€—è´¹è¾ƒé•¿æ—¶é—´ï¼Œ

- **è´å¶æ–¯è°ƒå‚**

  åœ¨ä½¿ç”¨ä¹‹å‰éœ€è¦å…ˆå®‰è£…åŒ…bayesian-optimizationï¼Œè¿è¡Œå¦‚ä¸‹å‘½ä»¤å³å¯ï¼š

  ```
  pip install bayesian-optimization
  ```

  è´å¶æ–¯è°ƒå‚çš„ä¸»è¦æ€æƒ³æ˜¯ï¼šç»™å®šä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°(å¹¿ä¹‰çš„å‡½æ•°ï¼Œåªéœ€æŒ‡å®šè¾“å…¥å’Œè¾“å‡ºå³å¯ï¼Œæ— éœ€çŸ¥é“å†…éƒ¨ç»“æ„ä»¥åŠæ•°å­¦æ€§è´¨)ï¼Œé€šè¿‡ä¸æ–­åœ°æ·»åŠ æ ·æœ¬ç‚¹æ¥æ›´æ–°ç›®æ ‡å‡½æ•°çš„åéªŒåˆ†å¸ƒ(é«˜æ–¯è¿‡ç¨‹,ç›´åˆ°åéªŒåˆ†å¸ƒåŸºæœ¬è´´åˆäºçœŸå®åˆ†å¸ƒï¼‰ã€‚ç®€å•çš„è¯´ï¼Œå°±æ˜¯è€ƒè™‘äº†ä¸Šä¸€æ¬¡å‚æ•°çš„ä¿¡æ¯ï¼Œä»è€Œæ›´å¥½çš„è°ƒæ•´å½“å‰çš„å‚æ•°ã€‚

  è´å¶æ–¯è°ƒå‚çš„æ­¥éª¤å¦‚ä¸‹ï¼š

  - å®šä¹‰ä¼˜åŒ–å‡½æ•°(rf_cvï¼‰
  - å»ºç«‹æ¨¡å‹
  - å®šä¹‰å¾…ä¼˜åŒ–çš„å‚æ•°
  - å¾—åˆ°ä¼˜åŒ–ç»“æœï¼Œå¹¶è¿”å›è¦ä¼˜åŒ–çš„åˆ†æ•°æŒ‡æ ‡

  ```python
  from sklearn.model_selection import cross_val_score
  
  """å®šä¹‰ä¼˜åŒ–å‡½æ•°"""
  def rf_cv_lgb(num_leaves, max_depth, bagging_fraction, feature_fraction, bagging_freq, min_data_in_leaf, 
                min_child_weight, min_split_gain, reg_lambda, reg_alpha):
      # å»ºç«‹æ¨¡å‹
      model_lgb = lgb.LGBMClassifier(boosting_type='gbdt', bjective='binary', metric='auc',
                                     learning_rate=0.1, n_estimators=5000,
                                     num_leaves=int(num_leaves), max_depth=int(max_depth), 
                                     bagging_fraction=round(bagging_fraction, 2), feature_fraction=round(feature_fraction, 2),
                                     bagging_freq=int(bagging_freq), min_data_in_leaf=int(min_data_in_leaf),
                                     min_child_weight=min_child_weight, min_split_gain=min_split_gain,
                                     reg_lambda=reg_lambda, reg_alpha=reg_alpha,
                                     n_jobs= 8
                                    )
      
      val = cross_val_score(model_lgb, X_train_split, y_train_split, cv=5, scoring='roc_auc').mean()
      
      return val
  ```

  ```python
  from bayes_opt import BayesianOptimization
  """å®šä¹‰ä¼˜åŒ–å‚æ•°"""
  bayes_lgb = BayesianOptimization(
      rf_cv_lgb, 
      {
          'num_leaves':(10, 200),
          'max_depth':(3, 20),
          'bagging_fraction':(0.5, 1.0),
          'feature_fraction':(0.5, 1.0),
          'bagging_freq':(0, 100),
          'min_data_in_leaf':(10,100),
          'min_child_weight':(0, 10),
          'min_split_gain':(0.0, 1.0),
          'reg_alpha':(0.0, 10),
          'reg_lambda':(0.0, 10),
      }
  )
  
  """å¼€å§‹ä¼˜åŒ–"""
  bayes_lgb.maximize(n_iter=10)
  ```

  ```
  |   iter    |  target   | baggin... | baggin... | featur... | max_depth | min_ch... | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |
  -------------------------------------------------------------------------------------------------------------------------------------------------
  | [0m 1       [0m | [0m 0.7263  [0m | [0m 0.7196  [0m | [0m 80.73   [0m | [0m 0.7988  [0m | [0m 19.17   [0m | [0m 5.751   [0m | [0m 40.71   [0m | [0m 0.9548  [0m | [0m 176.2   [0m | [0m 2.939   [0m | [0m 7.212   [0m |
  | [95m 2       [0m | [95m 0.7279  [0m | [95m 0.8997  [0m | [95m 74.72   [0m | [95m 0.5904  [0m | [95m 7.259   [0m | [95m 6.175   [0m | [95m 92.03   [0m | [95m 0.4027  [0m | [95m 51.65   [0m | [95m 6.404   [0m | [95m 4.781   [0m |
  | [0m 3       [0m | [0m 0.7207  [0m | [0m 0.5133  [0m | [0m 16.53   [0m | [0m 0.9536  [0m | [0m 4.974   [0m | [0m 2.37    [0m | [0m 98.08   [0m | [0m 0.7909  [0m | [0m 52.12   [0m | [0m 4.443   [0m | [0m 4.429   [0m |
  | [0m 4       [0m | [0m 0.7276  [0m | [0m 0.6265  [0m | [0m 53.12   [0m | [0m 0.7307  [0m | [0m 10.67   [0m | [0m 1.824   [0m | [0m 18.98   [0m | [0m 0.954   [0m | [0m 60.47   [0m | [0m 6.963   [0m | [0m 1.999   [0m |
  | [0m 5       [0m | [0m 0.6963  [0m | [0m 0.6509  [0m | [0m 11.58   [0m | [0m 0.5386  [0m | [0m 11.21   [0m | [0m 7.85    [0m | [0m 11.4    [0m | [0m 0.4269  [0m | [0m 153.0   [0m | [0m 0.5227  [0m | [0m 2.257   [0m |
  | [0m 6       [0m | [0m 0.7276  [0m | [0m 0.6241  [0m | [0m 49.76   [0m | [0m 0.6057  [0m | [0m 10.34   [0m | [0m 1.718   [0m | [0m 22.43   [0m | [0m 0.8294  [0m | [0m 55.68   [0m | [0m 6.759   [0m | [0m 2.6     [0m |
  | [95m 7       [0m | [95m 0.7283  [0m | [95m 0.9815  [0m | [95m 96.15   [0m | [95m 0.6961  [0m | [95m 19.45   [0m | [95m 1.627   [0m | [95m 37.7    [0m | [95m 0.4185  [0m | [95m 14.22   [0m | [95m 7.057   [0m | [95m 9.924   [0m |
  | [0m 8       [0m | [0m 0.7278  [0m | [0m 0.7139  [0m | [0m 96.83   [0m | [0m 0.5063  [0m | [0m 3.941   [0m | [0m 1.469   [0m | [0m 97.28   [0m | [0m 0.07553 [0m | [0m 196.9   [0m | [0m 7.988   [0m | [0m 2.159   [0m |
  | [0m 9       [0m | [0m 0.7195  [0m | [0m 0.5352  [0m | [0m 98.72   [0m | [0m 0.9699  [0m | [0m 4.445   [0m | [0m 1.767   [0m | [0m 13.91   [0m | [0m 0.1647  [0m | [0m 191.5   [0m | [0m 4.003   [0m | [0m 2.027   [0m |
  | [0m 10      [0m | [0m 0.7281  [0m | [0m 0.7281  [0m | [0m 73.63   [0m | [0m 0.5598  [0m | [0m 19.29   [0m | [0m 0.5344  [0m | [0m 99.66   [0m | [0m 0.933   [0m | [0m 101.4   [0m | [0m 8.836   [0m | [0m 0.9222  [0m |
  | [0m 11      [0m | [0m 0.7279  [0m | [0m 0.8213  [0m | [0m 0.05856 [0m | [0m 0.7626  [0m | [0m 17.49   [0m | [0m 8.447   [0m | [0m 10.71   [0m | [0m 0.3252  [0m | [0m 13.64   [0m | [0m 9.319   [0m | [0m 0.4747  [0m |
  | [0m 12      [0m | [0m 0.7281  [0m | [0m 0.8372  [0m | [0m 95.71   [0m | [0m 0.9598  [0m | [0m 10.32   [0m | [0m 8.394   [0m | [0m 15.23   [0m | [0m 0.4909  [0m | [0m 94.48   [0m | [0m 9.486   [0m | [0m 9.044   [0m |
  | [0m 13      [0m | [0m 0.6993  [0m | [0m 0.5183  [0m | [0m 99.02   [0m | [0m 0.542   [0m | [0m 15.5    [0m | [0m 8.35    [0m | [0m 38.15   [0m | [0m 0.4079  [0m | [0m 58.01   [0m | [0m 0.2668  [0m | [0m 1.652   [0m |
  | [0m 14      [0m | [0m 0.7267  [0m | [0m 0.7933  [0m | [0m 4.459   [0m | [0m 0.79    [0m | [0m 7.557   [0m | [0m 2.43    [0m | [0m 27.91   [0m | [0m 0.8725  [0m | [0m 28.32   [0m | [0m 9.967   [0m | [0m 9.885   [0m |
  | [0m 15      [0m | [0m 0.6979  [0m | [0m 0.9419  [0m | [0m 1.22    [0m | [0m 0.835   [0m | [0m 11.56   [0m | [0m 9.962   [0m | [0m 93.79   [0m | [0m 0.018   [0m | [0m 197.6   [0m | [0m 9.711   [0m | [0m 3.78    [0m |
  =================================================================================================================================================
  ```

  ```python
  """æ˜¾ç¤ºä¼˜åŒ–ç»“æœ"""
  bayes_lgb.max
  ```

  ```
  {'target': 0.7282530196283977,
   'params': {'bagging_fraction': 0.9815471914843896,
    'bagging_freq': 96.14757648686668,
    'feature_fraction': 0.6961281791730929,
    'max_depth': 19.45450235568963,
    'min_child_weight': 1.6266132496156782,
    'min_data_in_leaf': 37.697878831472295,
    'min_split_gain': 0.4184947943942168,
    'num_leaves': 14.221122487200399,
    'reg_alpha': 7.056502173310882,
    'reg_lambda': 9.924023764203156}}
  ```

  å‚æ•°ä¼˜åŒ–å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®ä¼˜åŒ–åçš„å‚æ•°å»ºç«‹æ–°çš„æ¨¡å‹ï¼Œé™ä½å­¦ä¹ ç‡å¹¶å¯»æ‰¾æœ€ä¼˜æ¨¡å‹è¿­ä»£æ¬¡æ•°

  ```python
  """è°ƒæ•´ä¸€ä¸ªè¾ƒå°çš„å­¦ä¹ ç‡ï¼Œå¹¶é€šè¿‡cvå‡½æ•°ç¡®å®šå½“å‰æœ€ä¼˜çš„è¿­ä»£æ¬¡æ•°"""
  base_params_lgb = {
                      'boosting_type': 'gbdt',
                      'objective': 'binary',
                      'metric': 'auc',
                      'learning_rate': 0.01,
                      'num_leaves': 14,
                      'max_depth': 19,
                      'min_data_in_leaf': 37,
                      'min_child_weight':1.6,
                      'bagging_fraction': 0.98,
                      'feature_fraction': 0.69,
                      'bagging_freq': 96,
                      'reg_lambda': 9,
                      'reg_alpha': 7,
                      'min_split_gain': 0.4,
                      'nthread': 8,
                      'seed': 2020,
                      'silent': True,
                      'verbose': -1,
  }
  
  cv_result_lgb = lgb.cv(
      train_set=train_matrix,
      early_stopping_rounds=1000, 
      num_boost_round=20000,
      nfold=5,
      stratified=True,
      shuffle=True,
      params=base_params_lgb,
      metrics='auc',
      seed=0
  )
  
  print('è¿­ä»£æ¬¡æ•°{}'.format(len(cv_result_lgb['auc-mean'])))
  print('æœ€ç»ˆæ¨¡å‹çš„AUCä¸º{}'.format(max(cv_result_lgb['auc-mean'])))
  ```

  ```
  è¿­ä»£æ¬¡æ•°14269
  æœ€ç»ˆæ¨¡å‹çš„AUCä¸º0.7315032037635779
  ```

  **æ¨¡å‹å‚æ•°å·²ç»ç¡®å®šï¼Œå»ºç«‹æœ€ç»ˆæ¨¡å‹å¹¶å¯¹éªŒè¯é›†è¿›è¡ŒéªŒè¯**

  ```python
  import lightgbm as lgb
  """ä½¿ç”¨lightgbm 5æŠ˜äº¤å‰éªŒè¯è¿›è¡Œå»ºæ¨¡é¢„æµ‹"""
  cv_scores = []
  for i, (train_index, valid_index) in enumerate(kf.split(X_train, y_train)):
      print('************************************ {} ************************************'.format(str(i+1)))
      X_train_split, y_train_split, X_val, y_val = X_train.iloc[train_index], y_train[train_index], X_train.iloc[valid_index], y_train[valid_index]
      
      train_matrix = lgb.Dataset(X_train_split, label=y_train_split)
      valid_matrix = lgb.Dataset(X_val, label=y_val)
  
      params = {
                  'boosting_type': 'gbdt',
                  'objective': 'binary',
                  'metric': 'auc',
                  'learning_rate': 0.01,
                  'num_leaves': 14,
                  'max_depth': 19,
                  'min_data_in_leaf': 37,
                  'min_child_weight':1.6,
                  'bagging_fraction': 0.98,
                  'feature_fraction': 0.69,
                  'bagging_freq': 96,
                  'reg_lambda': 9,
                  'reg_alpha': 7,
                  'min_split_gain': 0.4,
                  'nthread': 8,
                  'seed': 2020,
                  'silent': True,
      }
      
      model = lgb.train(params, train_set=train_matrix, num_boost_round=14269, valid_sets=valid_matrix, verbose_eval=1000, early_stopping_rounds=200)
      val_pred = model.predict(X_val, num_iteration=model.best_iteration)
      
      cv_scores.append(roc_auc_score(y_val, val_pred))
      print(cv_scores)
  
  print("lgb_scotrainre_list:{}".format(cv_scores))
  print("lgb_score_mean:{}".format(np.mean(cv_scores)))
  print("lgb_score_std:{}".format(np.std(cv_scores)))
  ```

  ```
  ...
  lgb_scotrainre_list:[0.7329726464187137, 0.7294292852806246, 0.7341505801564857, 0.7328331383185244, 0.7317405262608612]
  lgb_score_mean:0.732225235287042
  lgb_score_std:0.0015929470575114753
  ```

  é€šè¿‡5æŠ˜äº¤å‰éªŒè¯å¯ä»¥å‘ç°ï¼Œæ¨¡å‹è¿­ä»£æ¬¡æ•°åœ¨13000æ¬¡çš„æ—¶å€™ä¼šåœä¹‹ï¼Œé‚£ä¹ˆæˆ‘ä»¬åœ¨å»ºç«‹æ–°æ¨¡å‹æ—¶ç›´æ¥è®¾ç½®æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¹¶ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ¨¡å‹é¢„æµ‹

  ```python
  """"""
  base_params_lgb = {
                      'boosting_type': 'gbdt',
                      'objective': 'binary',
                      'metric': 'auc',
                      'learning_rate': 0.01,
                      'num_leaves': 14,
                      'max_depth': 19,
                      'min_data_in_leaf': 37,
                      'min_child_weight':1.6,
                      'bagging_fraction': 0.98,
                      'feature_fraction': 0.69,
                      'bagging_freq': 96,
                      'reg_lambda': 9,
                      'reg_alpha': 7,
                      'min_split_gain': 0.4,
                      'nthread': 8,
                      'seed': 2020,
                      'silent': True,
  }
  
  """ä½¿ç”¨è®­ç»ƒé›†æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒ"""
  final_model_lgb = lgb.train(base_params_lgb, train_set=train_matrix, valid_sets=valid_matrix, num_boost_round=13000, verbose_eval=1000, early_stopping_rounds=200)
  
  """é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
  val_pre_lgb = final_model_lgb.predict(X_val)
  fpr, tpr, threshold = metrics.roc_curve(y_val, val_pre_lgb)
  roc_auc = metrics.auc(fpr, tpr)
  print('è°ƒå‚ålightgbmå•æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„AUCï¼š{}'.format(roc_auc))
  """ç”»å‡ºrocæ›²çº¿å›¾"""
  plt.figure(figsize=(8, 8))
  plt.title('Validation ROC')
  plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)
  plt.ylim(0,1)
  plt.xlim(0,1)
  plt.legend(loc='best')
  plt.title('ROC')
  plt.ylabel('True Positive Rate')
  plt.xlabel('False Positive Rate')
  # ç”»å‡ºå¯¹è§’çº¿
  plt.plot([0,1],[0,1],'r--')
  plt.show()
  ```

  ```
  Training until validation scores don't improve for 200 rounds
  [1000]	valid_0's auc: 0.723676
  [2000]	valid_0's auc: 0.727282
  [3000]	valid_0's auc: 0.728593
  [4000]	valid_0's auc: 0.729493
  [5000]	valid_0's auc: 0.730087
  [6000]	valid_0's auc: 0.730515
  [7000]	valid_0's auc: 0.730872
  [8000]	valid_0's auc: 0.731121
  [9000]	valid_0's auc: 0.731351
  [10000]	valid_0's auc: 0.731502
  [11000]	valid_0's auc: 0.731707
  Early stopping, best iteration is:
  [11192]	valid_0's auc: 0.731741
  è°ƒå‚ålightgbmå•æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„AUCï¼š0.7317405262608612
  ```

![output_29_1.png](https://img-blog.csdnimg.cn/20200905094507951.png)

  å¯ä»¥çœ‹åˆ°ç›¸æ¯”æœ€æ—©çš„åŸå§‹å‚æ•°ï¼Œæ¨¡å‹çš„æ€§èƒ½è¿˜æ˜¯æœ‰æå‡çš„

  ```python
  """ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°"""
  # ä¿å­˜æ¨¡å‹
  import pickle
  pickle.dump(final_model_lgb, open('dataset/model_lgb_best.pkl', 'wb'))
  ```

- **æ¨¡å‹è°ƒå‚å°æ€»ç»“**

  - é›†æˆæ¨¡å‹å†…ç½®çš„cvå‡½æ•°å¯ä»¥è¾ƒå¿«çš„è¿›è¡Œå•ä¸€å‚æ•°çš„è°ƒèŠ‚ï¼Œä¸€èˆ¬å¯ä»¥ç”¨æ¥ä¼˜å…ˆç¡®å®šæ ‘æ¨¡å‹çš„è¿­ä»£æ¬¡æ•°

  - æ•°æ®é‡è¾ƒå¤§çš„æ—¶å€™ï¼ˆä¾‹å¦‚æœ¬æ¬¡é¡¹ç›®çš„æ•°æ®ï¼‰ï¼Œç½‘æ ¼æœç´¢è°ƒå‚ä¼šç‰¹åˆ«ç‰¹åˆ«æ…¢ï¼Œä¸å»ºè®®å°è¯•

  - é›†æˆæ¨¡å‹ä¸­åŸç”Ÿåº“å’Œsklearnä¸‹çš„åº“éƒ¨åˆ†å‚æ•°ä¸ä¸€è‡´ï¼Œéœ€è¦æ³¨æ„ï¼Œå…·ä½“å¯ä»¥å‚è€ƒxgbå’Œlgbçš„å®˜æ–¹API

    > [xgbåŸç”Ÿåº“API](https://xgboost.readthedocs.io/en/stable/parameter.html)ï¼Œ[sklearnåº“ä¸‹xgbAPI](https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.sklearn)
    >
    > [lgbåŸç”Ÿåº“API](https://lightgbm.readthedocs.io/en/latest/Parameters.html)ï¼Œ [sklearnåº“ä¸‹lgbAPI](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)



## 4.6 ç»éªŒæ€»ç»“

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å®Œæˆäº†å»ºæ¨¡ä¸è°ƒå‚çš„å·¥ä½œï¼Œé¦–å…ˆåœ¨å»ºæ¨¡çš„è¿‡ç¨‹ä¸­é€šè¿‡åˆ’åˆ†æ•°æ®é›†ã€äº¤å‰éªŒè¯ç­‰æ–¹å¼å¯¹æ¨¡å‹çš„æ€§èƒ½è¿›è¡Œè¯„ä¼°éªŒè¯ï¼Œå¹¶é€šè¿‡å¯è§†åŒ–æ–¹å¼ç»˜åˆ¶æ¨¡å‹ROCæ›²çº¿ã€‚

æœ€åæˆ‘ä»¬å¯¹æ¨¡å‹è¿›è¡Œè°ƒå‚ï¼Œè¿™éƒ¨åˆ†ä»‹ç»äº†è´ªå¿ƒè°ƒå‚ã€ç½‘æ ¼æœç´¢è°ƒå‚ã€è´å¶æ–¯è°ƒå‚å…±ä¸‰ç§è°ƒå‚æ‰‹æ®µï¼Œé‡ç‚¹ä½¿ç”¨è´å¶æ–¯è°ƒå‚å¯¹æœ¬æ¬¡é¡¹ç›®è¿›è¡Œç®€å•ä¼˜åŒ–ï¼Œå¤§å®¶åœ¨å®é™…æ“ä½œçš„è¿‡ç¨‹ä¸­å¯ä»¥å‚è€ƒè°ƒå‚æ€è·¯è¿›è¡Œä¼˜åŒ–ï¼Œä¸å¿…æ‹˜æ³¥äºä»¥ä¸Šæ•™ç¨‹æ‰€å†™çš„å…·ä½“å®ä¾‹ã€‚


