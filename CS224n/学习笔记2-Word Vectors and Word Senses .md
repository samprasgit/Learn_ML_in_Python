<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [GLoVe(Global Vectors for Word Representation)](#gloveglobal-vectors-for-word-representation)
- [Co-occurrence Matrix](#co-occurrence-matrix)
- [ç›®æ ‡å‡½æ•°](#%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## GLoVe(Global Vectors for Word Representation)

GloVe æ¨¡å‹åŒ…å«ä¸€ä¸ªè®­ç»ƒåœ¨å•è¯-å•è¯çš„å…±åŒå‡ºç°æ¬¡æ•°ä¸Šçš„åŠ æƒçš„æœ€å°äºŒä¹˜æ¨¡å‹

## Co-occurrence Matrix

å‡è®¾å•è¯ä¸å•è¯çš„ co-occurrence matrix çŸ©é˜µç”¨$X$è¡¨ç¤ºï¼Œğ‘‹ğ‘–ğ‘—è¡¨ç¤ºå•è¯ ğ‘—å‡ºç°åœ¨å•è¯$i$çš„ä¸Šä¸‹æ–‡ä¸­çš„æ¬¡æ•°ï¼Œ $X_{i}=\sum_{k} X_{i k}$è¡¨ç¤ºä»»ä½•ä¸€ä¸ªå•è¯ k å‡ºç°åœ¨å•è¯ i çš„ä¸Šä¸‹æ–‡ä¸­çš„æ¬¡æ•°ï¼Œ
$$
P_{i j}=P\left(w_{j} \mid w_{i}\right)=\frac{X_{i j}}{X_{i}}
$$
è¡¨ç¤ºå•è¯$j$å‡ºç°åœ¨å•è¯$i$ä¸Šä¸‹æ–‡ä¸­çš„æ¦‚ç‡,æ‰€ä»¥å¡«å……è¿™ä¸ªçŸ©é˜µéœ€è¦éå†ä¸€æ¬¡è¯­æ–™åº“

## ç›®æ ‡å‡½æ•°

åœ¨ skip-gramç®—æ³•ä¸­ï¼Œæˆ‘ä»¬åœ¨è¾“å‡ºå±‚ä½¿ç”¨çš„æ˜¯ ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ å‡½æ•°è®¡ç®—å•è¯$j$å‡ºç°åœ¨å•è¯$i$ä¸Šä¸‹æ–‡çš„æ¦‚ç‡
$$
Q_{i j}=\frac{\exp \left(\vec{u}_{j}^{T} \vec{v}_{i}\right)}{\sum_{w=1}^{W} \exp \left(\vec{u}_{w}^{T} \vec{v}_{i}\right)}
$$
å¦‚æœæˆ‘ä»¬å°†è¿™ä¸ªç”¨äºå…¨å±€çš„æ•°æ®çš„è¯ï¼Œé‚£ä¹ˆäº¤å‰ç†µæŸå¤±å‡½æ•°å°±å¯ä»¥è¿™ä¹ˆç®—ï¼š
$$
I=-\sum_{i \in \operatorname{corpus}} \sum_{j \in \text { context }(i)} \log Q_{i j}
$$
è¿™ä¸ªå…¬å¼çš„æœ¬è´¨å°±æ˜¯åœ¨ä¸Šä¸€èŠ‚è®²çš„ä¸€å¥è¯çš„skip-gramä¸Šä¸Šå‡åˆ°å¯¹æ•´ä¸ªæ–‡æœ¬çš„å¤„ç†ã€‚å¦‚æœæˆ‘ä»¬è€ƒè™‘å•è¯ä¸Šä¸‹æ–‡å¤§å°ä»¥åŠæ–‡æœ¬å¤§å°ä¸º ğ‘ŠW.é‚£ä¹ˆäº¤å‰ç†µæŸå¤±å‡½æ•°å¯ä»¥å†™æˆï¼š
$$
J=-\sum_{i=1}^{W} \sum_{j=1}^{W} X_{i j} \log Q_{i j}
$$
ä¸Šé¢å…¬å¼é¢ä¸´çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œåœ¨è®¡ç®—æ•´ä¸ªæ–‡æœ¬çš„æ—¶å€™ï¼Œè®¡ç®— ğ‘„ çš„ ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥å‡½æ•°ï¼Œè¿™ä¸ªè®¡ç®—é‡å¤ªå¤§äº†ã€‚æ‰€ä»¥ä¸‹é¢æƒ³åŠæ³•ä¼˜åŒ–ä¸€ä¸‹ï¼šæ‰€ä»¥æˆ‘ä»¬æ ¹æœ¬å°±ä¸ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œè€Œæ˜¯ä½¿ç”¨æœ€å°äºŒä¹˜æ³•ï¼Œé‚£ä¹ˆæŸå¤±å‡½æ•°å°±æ˜¯ä¸‹é¢è¿™æ ·ï¼š
$$
\hat{\jmath}=\sum_{i=1}^{W} \sum_{j=1}^{W} X_{i}\left(\hat{P}_{i j}-\hat{Q}_{i j}\right)^{2}
$$
å…¶ä¸­ $\hat{P}_{i j}=X_{i j}$ and $\hat{Q}_{i j}=\exp \left(\vec{u}_{j}^{T} \vec{v}_{i}\right)$æ˜¯éæ­£æ€åˆ†å¸ƒçš„. è¿™é‡Œçš„ ğ‘‹ğ‘–ğ‘— ç­‰ä»·äº j å‡ºç°åœ¨ i çš„ä¸Šä¸‹æ–‡çš„æ¬¡æ•°ï¼Œ è€Œ ğ‘„Ì‚ ğ‘–ğ‘—æ˜¯æˆ‘ä»¬é€šè¿‡ skip-gram é¢„æµ‹çš„æ¬¡æ•°ï¼Œæ‰€ä»¥æ˜¯æœ€å°äºŒä¹˜æ³•ã€‚è¿™æ ·çš„è®¡ç®—é‡è¿˜æ˜¯å¾ˆå¤§ï¼Œä¹ æƒ¯ä¸Šå–ä¸ªå¯¹æ•°ï¼Œå…¬å¼å°±å˜æˆä¸‹é¢è¿™æ ·äº†ï¼š
$$
\begin{aligned}
\hat{J} &=\sum_{i=1}^{W} \sum_{j=1}^{W} X_{i}\left(\log (\hat{P})_{i j}-\log \left(\hat{Q}_{i j}\right)\right)^{2} \\
&=\sum_{i=1}^{W} \sum_{j=1}^{W} X_{i}\left(\vec{u}_{j}^{T} \vec{v}_{i}-\log X_{i j}\right)^{2}
\end{aligned}
$$
ä¸Šé¢çš„å…¬å¼ä¸­ç›´æ¥ä½¿ç”¨ ğ‘‹ğ‘–ä¸ä¸€å®šèƒ½å¤Ÿè¾¾åˆ°æœ€ä¼˜ï¼Œå› æ­¤æˆ‘ä»¬é€‰æ‹© ğ‘“(ğ‘‹ğ‘–ğ‘—)ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡æ¥è¡¨ç¤ºä»¥æé«˜å‡†ç¡®ç‡ï¼š
$$
\hat{\jmath}=\sum_{i=1}^{W} \sum_{j=1}^{W} f\left(X_{i j}\right)\left(\vec{u}_{j}^{T} \vec{v}_{i}-\log X_{i j}\right)^{2}
$$
